# Obiekt StatefulSets â€“ Ä†wiczenia

### Na podstawie lekcji przetestuj:

- Tworzenie i aktualizacjÄ™ StatefulSets
- DziaÅ‚anie serwisu typu headless
- Skalowanie StatefulSets

PoÅ‚Ä…cz wiedzÄ™ na temat kontenera typu init oraz wolumenÃ³w z StatefulSets. Za pomocÄ… kontenera typu init pobierz stronÄ™ z repozytorium git. Pobrane dane muszÄ… trafiÄ‡ na trwaÅ‚y wolumen i zostaÄ‡ wykorzystane do serwowania treÅ›ci w gÅ‚Ã³wnym kontenerze (wykorzystaj nginx). Skorzystaj z materiaÅ‚Ã³w po Ä‡wiczeniach o kontenera typu init.

---

### Tworzenie i aktualizacjÄ™ StatefulSets

Manifest dna naszego statefulset
```
apiversion: apps/v1
kind: StatefulSet
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchlabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      initContainers:
      - image: ubuntu:latest
        name: setup
        volumeMounts:
          - name: workdir
            mountPath: /repo
        command: ["/bin/sh", "-c"]
        args:
          - apt-get update;
            apt-get install -y git;
            git clone "https://github.com/KrzyskowK/poznajKubernetes.git" /repo;
    containers:
      - image: nginx:1.17.6
        name: nginx
        ports:
          - containerPort: 80
        volumeMounts:
          - name: workdir
            mountPath: /usr/share/nginx/html
    volumes:
      - name: workdir
        emptyDir: {}
```

Wgrywamy konfiguracjÄ™ na klaster
```
> kubectl apply -f .\statefulset.yaml
statefulset.apps/nginx created
```
Obserwujemy jak kolejno tworzone sÄ… instancje podÃ³w `nginx-0`, `nginx-1`, `nginx-2`

```
> kubectl get statefulset -w
NAME    READY   AGE
nginx   0/3     0s
nginx   0/3     0s
nginx   1/3     40s
nginx   2/3     81s
nginx   3/3     118s

> kubectl get pod -w
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   0/1     Pending   0          0s
nginx-0   0/1     Pending   0          0s
nginx-0   0/1     Init:0/1   0          0s
nginx-0   0/1     Init:0/1   0          4s
nginx-0   0/1     PodInitializing   0          38s
nginx-0   1/1     Running           0          40s
nginx-1   0/1     Pending           0          0s
nginx-1   0/1     Pending           0          0s
nginx-1   0/1     Init:0/1          0          0s
nginx-1   0/1     Init:0/1          0          4s
nginx-1   0/1     PodInitializing   0          40s
nginx-1   1/1     Running           0          41s
nginx-2   0/1     Pending           0          0s
nginx-2   0/1     Pending           0          0s
nginx-2   0/1     Init:0/1          0          0s
nginx-2   0/1     Init:0/1          0          4s
nginx-2   0/1     PodInitializing   0          36s
nginx-2   1/1     Running           0          37s
```
SprawdÅºmy co siÄ™ stanie jeÅ¼eli teraz sprÃ³bujemy usunÄ…Ä‡ instancjÄ™ `nginx-1`
```
> kubectl delete pod nginx-1
pod "nginx-1" deleted

> kubectl get pod -w
NAME      READY   STATUS    RESTARTS   AGE
nginx-1   1/1     Terminating       0          10m
nginx-1   0/1     Terminating       0          10m
nginx-1   0/1     Terminating       0          10m
nginx-1   0/1     Terminating       0          10m
nginx-1   0/1     Pending           0          0s
nginx-1   0/1     Pending           0          0s
nginx-1   0/1     Init:0/1          0          0s
nginx-1   0/1     Init:0/1          0          5s
nginx-1   0/1     PodInitializing   0          44s
nginx-1   1/1     Running           0          45s
```
`nginx-1` zostaje odtworzony przez statefulset

SprÃ³bujmy teraz zamieniÄ‡ `volumen` z `emptyDir` na `PersistenVolumeClaim`.
Dodajemy do spec sekcjÄ™ `volueClaimTemplates` ktÃ³ra utworzyc PVC ktÃ³re powinno skorzystaÄ‡ z defaultowego PeristentVolumeProvisioner do stowrzenia odpowiedniego PersistanVolume.
```
  volumeClaimTemplates:
    - metadata:
        name: workdir
      spec:
        accessModes: [ "ReadWriteOnce"]
        resources:
          requests:
            storage: 10Mi
```
âš ï¸ dodatkowo z templatu poda caÅ‚kowicie usuwamy sekcjÄ™ volumes!

PrÃ³bujemy teraz zaktualizowaÄ‡ naszÄ… konfiguracjÄ™ - co niestety nie powiedzie siÄ™ 
```
> kubectl apply -f .\statefulset-pvc.yaml
The StatefulSet "nginx" is invalid: spec: Forbidden: updates to statefulset spec for fields other than 'replicas', 'template', and 'updateStrategy' are forbidden
```
SprÃ³bujmy zatem usunÄ…Ä‡ statefulset bez usuwania podÃ³w
```
> kubectl delete statefulset nginx --cascade=false
statefulset.apps "nginx" deleted

> kubectl get pod
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   1/1     Running   0          28m
nginx-1   1/1     Running   0          16m
nginx-2   1/1     Running   0          26m

> kubectl get statefulset
No resources found.
```
Dodajemy teraz konfiguracjÄ™ ponownie
```
> kubectl apply -f .\statefulset-pvc.yaml
statefulset.apps/nginx created
```

Widzimy, Å¼e PV i PVC zotaly utworzone zgodnie z templatem, jednak tylko dla pierwszego pod `nginx-0`
```
> kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                  STORAGECLASS   REASON   AGE
pvc-39fe1bb9-43a5-11ea-b471-00155d006a01   10Mi       RWO            Delete           Bound    default/workdir-nginx-0   hostpath                65s

> kubectl get pvc
NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
workdir-nginx-0   Bound    pvc-39fe1bb9-43a5-11ea-b471-00155d006a01   10Mi       RWO            hostpath       68s
```
Statefulset nie byÅ‚ w stanie zaktualizowaÄ‡ podÃ³w automatycznie 
Powodem tego moÅ¼emy znaleÅºÄ‡ w eventach statefulset - podmiana volumeMount nie jest obslugiwana przez automatyczny rollout.
```
> kubectl get statefulset
NAME    READY   AGE
nginx   0/3     38s

> kubectl rollout history statefulset nginx
statefulset.apps/nginx 
REVISION
0
1

> kubectl describe statefulset nginx
...
Events:
  Type     Reason            Age                From                    Message
  ----     ------            ----               ----                    -------
  Normal   SuccessfulCreate  23s                statefulset-controller  create Claim workdir-nginx-0 Pod nginx-0 in StatefulSet nginx success
  Warning  FailedUpdate      3s (x14 over 23s)  statefulset-controller  update Pod nginx-0 in StatefulSet nginx failed error: Pod "nginx-0" is invalid: spec: Forbidden: pod updates may not change fields other than `spec.containers[*].image`, `spec.initContainers[*].image`, `spec.activeDeadlineSeconds` or `spec.tolerations` (only additions to existing tolerations)
{"Volumes":[{"Name":"workdir","HostPath":null,"EmptyDir": ....
```
sprÃ³bujmy usunÄ…Ä‡ rÄ™cznie ostatni pod i sprawdziÄ‡ czy statefulset oddtworzy `ngnix-2` w nowej wersji
```
> kubectl delete pod nginx-2
pod "nginx-2" deleted

> kubectl get pod
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   1/1     Running   0          65m
nginx-1   1/1     Running   0          54m

> kubectl get statefulset
NAME    READY   AGE
nginx   0/3     19m
```
âš ï¸ Widzimy, Å¼e pomimo rÄ™cznego usuniÄ™cia pod nie zostaÅ‚ odtworzony. 

ğŸ’¡ Przypomnijmy sobie jednak, Å¼e statefulset w obecnej konfiguracji zawsze rozpoczyna "Å›wieÅ¼y" deployment od pierwszego indeksu, sprawdÅºmy zatem czy usuniÄ™cie `nginx-0` spowoduje deployment nowej wersji

```
> kubectl delete pod nginx-0
pod "nginx-0" deleted

> kubectl get pod -w
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   0/1     Terminating   0          8m19s
nginx-0   0/1     Pending       0          0s
nginx-0   0/1     Pending       0          0s
nginx-0   0/1     Init:0/1      0          0s
nginx-0   0/1     Init:0/1      0          4s
nginx-0   0/1     PodInitializing   0          43s
nginx-0   1/1     Running           0          44s

> kubectl get statefulset
NAME    READY   AGE
nginx   1/3     7m14s
```

UsuÅ„my zatem kolejny pod `nginx-1` i pozwÃ³lmyna dokoÅ„czenie rolloutu nowej wersji.

Widzimy, Å¼e pozostaÅ‚e pody zostajÄ… poprawnie utworzone. PV i PVC sÄ… teraz rÃ³wnieÅ¼ dostÄ™pne dla wszystkich podÃ³w.
```
> kubectl delete pod nginx-1
pod "nginx-1" deleted

> kubectl get pod
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   1/1     Running   0          11m
nginx-1   1/1     Running   0          3m
nginx-2   1/1     Running   0          2m20s

> kubectl get statefulset
NAME    READY   AGE
nginx   3/3     14m

> kubectl get pvc
NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
workdir-nginx-0   Bound    pvc-39fe1bb9-43a5-11ea-b471-00155d006a01   10Mi       RWX            hostpath       14m
workdir-nginx-1   Bound    pvc-d80c4202-43a5-11ea-b471-00155d006a01   10Mi       RWX            hostpath       10m
workdir-nginx-2   Bound    pvc-f3ceb5ba-43a6-11ea-b471-00155d006a01   10Mi       RWX            hostpath       2m31s

> kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS   REASON   AGE
pvc-39fe1bb9-43a5-11ea-b471-00155d006a01   10Mi       RWX            Delete           Bound    default/workdir-nginx-0   hostpath                15m
pvc-d80c4202-43a5-11ea-b471-00155d006a01   10Mi       RWX            Delete           Bound    default/workdir-nginx-1   hostpath                10m
pvc-f3ceb5ba-43a6-11ea-b471-00155d006a01   10Mi       RWX            Delete           Bound    default/workdir-nginx-2   hostpath                2m42s
```

SprawdÅºmy teraz czy przy aktualizacji wersji obrazu (`nginx:1.17.6 -> 1.17`) startegia rollingUpdate zadziaÅ‚a zgodnie z oczekiwaniami.

```
> kubectl apply -f .\statefulset-pvc.yaml
statefulset.apps/nginx configured

> kubectl get pod -w
NAME      READY   STATUS     RESTARTS   AGE
nginx-0   1/1     Running    0          18m
nginx-1   1/1     Running    0          10m
nginx-2   0/1     Init:0/1   0          4s
nginx-2   0/1     Init:0/1   0          5s
nginx-2   0/1     Init:Error   0          42s
nginx-2   0/1     Init:0/1     1          45s
```

Rollout rozpoczyna siÄ™ od ostatniego poda. Widzimy jednak, Å¼e pod `nginx-02` ma problem z inicjalizacjÄ…. SprawdÅºmy zatem logi.

```
> kubectl attach pod nginx-2 -c setup

...
Setting up git (1:2.17.1-1ubuntu0.5) ...
Processing triggers for libc-bin (2.27-3ubuntu1) ...
Processing triggers for ca-certificates (20180409) ...
Updating certificates in /etc/ssl/certs...
0 added, 0 removed; done.
Running hooks in /etc/ca-certificates/update.d...
done.
fatal: destination path '/repo' already exists and is not an empty directory.
```
W logach widaÄ‡, Å¼e `initContainer` nie potrafi pobraÄ‡ repozytorium do folderu /repo poniewaÅ¼ folder juÅ¼ istnieje. 

âš ï¸ CaÅ‚a sytuacja jest oczywista, korzystajÄ…c z PV zatem nasze /repo bÄ™dzie usuwane przy podmianie podÃ³w (np przy deploymencie) w zwiÄ…zku z tym musimy obsÅ‚uÅ¼yÄ‡ ten przypadek Å¼eby InitContainer mÃ³gÅ‚ zakoÅ„czyÄ‡ siÄ™ sukcesem
```
  args:
    - apt-get update;
    apt-get install -y git;
    if cd repo; 
    then git pull;
    else git clone "https://github.com/KrzyskowK/poznajKubernetes.git" /repo;
    fi
```

Widzimy, Å¼e tym razem wszystkie pod zostaÅ‚u poprawnie zaktualizowane w kolejnoÅ›ci od najwiÄ™kszego indeksu do najmniejszego
```
> kubectl apply -f .\statefuset-pvc-release-fixed.yaml
statefulset.apps/nginx configured

> kubectl get pod
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   1/1     Running   0          103s
nginx-1   1/1     Running   0          2m33s
nginx-2   1/1     Running   0          3m23s

> kubectl get pod nginx-0 -o jsonpath="{..containers[:1].image}"
nginx:1.17
> kubectl get pod nginx-1 -o jsonpath="{..containers[:1].image}"
nginx:1.17
> kubectl get pod nginx-2 -o jsonpath="{..containers[:1].image}"
nginx:1.17

```

### DziaÅ‚anie serwisu typu headless